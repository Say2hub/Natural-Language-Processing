{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###*60009220131 Sayantan Mukherjee D2-2*"
      ],
      "metadata": {
        "id": "w18K2tNBiYiE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaH7RNB9YyUa",
        "outputId": "8ce191bb-13aa-4cb9-a364-699497fd067c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Hello, I'm Sayantan Mukherjee.\", \"I'm Currently in DJSCE As a Third-Year BTECH Student.\", 'I have passed 5 Semesters.']\n",
            "['Hello', ',', 'I', \"'m\", 'Sayantan', 'Mukherjee', '.', 'I', \"'m\", 'Currently', 'in', 'DJSCE', 'As', 'a', 'Third-Year', 'BTECH', 'Student', '.', 'I', 'have', 'passed', '5', 'Semesters', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "text=\"Hello, I'm Sayantan Mukherjee. I'm Currently in DJSCE As a Third-Year BTECH Student. I have passed 5 Semesters.\"\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Bengali text tokenized form*"
      ],
      "metadata": {
        "id": "4fOWWEyFkIm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "text=\"আমি একজন ছাত্র। আমি বাংলা ভাষা শিখতে ভালোবাসি।\"\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10YVW7KeiXYz",
        "outputId": "838195c5-826c-489e-dba6-20aee26d1d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['আমি একজন ছাত্র। আমি বাংলা ভাষা শিখতে ভালোবাসি।']\n",
            "['আমি', 'একজন', 'ছাত্র।', 'আমি', 'বাংলা', 'ভাষা', 'শিখতে', 'ভালোবাসি।']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lower Case\n"
      ],
      "metadata": {
        "id": "0_0wunS7d8ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "print(text.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzJKvke6Z6oL",
        "outputId": "a8f46c58-58f1-49e6-d446-0248a65f40f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello, i'm sayantan mukherjee. i'm currently in djsce as a third-year btech student. i have passed 5 semesters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Number Removed"
      ],
      "metadata": {
        "id": "LKpqsicweLIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub('\\d+',\"\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrFuw08vaDyD",
        "outputId": "d704ebd7-da43-4bbd-cd95-9b1ef0377298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'আমি একজন ছাত্র। আমি বাংলা ভাষা শিখতে ভালোবাসি।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Number to Words"
      ],
      "metadata": {
        "id": "zTbKN_87eOMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inflect\n",
        "p=inflect.engine()\n",
        "temp_str=text.split()\n",
        "new_string=[]\n",
        "for word in temp_str:\n",
        "  if word.isdigit():\n",
        "    temp=p.number_to_words(word)\n",
        "    new_string.append(temp)\n",
        "  else:\n",
        "    new_string.append(word)\n",
        "\n",
        "answer=' '.join(new_string)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtZzna0daxhc",
        "outputId": "5e465192-c623-4832-940b-74bd567b00da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I'm Sayantan Mukherjee. I'm Currently in DJSCE As a Third-Year BTECH Student. I have passed five Semesters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Punctuations Removed"
      ],
      "metadata": {
        "id": "ZXsW9xNYeSub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str= \"Hey , Did you Know that Earth?! is   Oval ??!!\"\n",
        "translator = str.maketrans(\"\",\"\",string.punctuation)\n",
        "print(str.translate(translator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWx18dxpbTxT",
        "outputId": "1dfcd3e6-3699-4eae-aa51-cd1409ba4db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey  Did you Know that Earth is   Oval \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Space Removed"
      ],
      "metadata": {
        "id": "9uZu3e9yeV7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_spaces_text = text.replace(\" \", \"\")\n",
        "print(no_spaces_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-Inpl4obyDd",
        "outputId": "8715e100-9787-40ca-9c15-53d844b3c6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello,I'mSayantanMukherjee.I'mCurrentlyinDJSCEAsaThird-YearBTECHStudent.Ihavepassed5Semesters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stop Words: is,an,the Removed"
      ],
      "metadata": {
        "id": "_yLhH3eHebdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "def remove_stopwords(text):\n",
        "  stop_words=set(stopwords.words(\"english\"))\n",
        "  word_tokens=word_tokenize(text)\n",
        "  filtered_text=[word for word in word_tokens if word not in stop_words]\n",
        "  return filtered_text\n",
        "\n",
        "print(remove_stopwords(str))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z98HSei7b9qs",
        "outputId": "5e1130b3-721d-41d1-82d8-f52cbbde6737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hey', ',', 'Did', 'Know', 'Earth', '?', '!', 'Oval', '?', '?', '!', '!']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Regional Language- Bengali*"
      ],
      "metadata": {
        "id": "kbybfOmPlfYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"আমি একজন ছাত্র এবং আমি বাংলা ভাষা শিখতে ভালোবাসি।\"\n",
        "\n",
        "\"\"\"\n",
        "English Translation: \"Student love learning Bengali language.\"\n",
        "\n",
        "\"\n"
      ],
      "metadata": {
        "id": "GjDYsUvQmVpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [\"আমি\", \"এবং\", \"একজন\", \"এ\", \"ও\", \"তারা\", \"যা\", \"ছিল\", \"বা\", \"এই\", \"যে\"]\n",
        "def remove_stop_words(text, stop_words):\n",
        "    # Tokenize the text\n",
        "    word_list = text.split()\n",
        "    # Remove stop words\n",
        "    filtered_words = [word for word in word_list if word not in stop_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "filtered_text = remove_stop_words(text, stop_words)\n",
        "print(\"Text after removing stop words:\", filtered_text)\n",
        "\n",
        "# English translation after removing stop words\n",
        "english_translation = \"Student love learning Bengali language.\"\n",
        "print(\"English Translation:\", english_translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw9Ba0pGltdL",
        "outputId": "2083ed13-da3d-483d-ae5a-1795613b2502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text after removing stop words: ছাত্র বাংলা ভাষা শিখতে ভালোবাসি।\n",
            "English Translation: Student love learning Bengali language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Count"
      ],
      "metadata": {
        "id": "89d8MT0Ji6ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "text = \"Hello, I'm Sayantan Mukherjee. I'm Currently in DJSCE As a Third-Year BTECH Student. I have passed 5 Semesters.\"\n",
        "\n",
        "# Removing punctuation and converting to lower case\n",
        "text_cleaned = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "word_list = text_cleaned.split()\n",
        "\n",
        "# Counting word frequency\n",
        "word_freq = Counter(word_list)\n",
        "print(\"Word Frequency:\", word_freq)\n"
      ],
      "metadata": {
        "id": "It_U4iE3dM9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e8d712-b832-49fc-9170-fedd2171ce01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequency: Counter({'im': 2, 'hello': 1, 'sayantan': 1, 'mukherjee': 1, 'currently': 1, 'in': 1, 'djsce': 1, 'as': 1, 'a': 1, 'thirdyear': 1, 'btech': 1, 'student': 1, 'i': 1, 'have': 1, 'passed': 1, '5': 1, 'semesters': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming\n",
        "\n",
        "1-Porter Stemmer\n",
        "\n",
        "2-Lancaster Stemmer\n",
        "\n",
        "Stemming is a text normalization technique in NLP that reduces words to their root or base form. Unlike lemmatization, stemming cuts off prefixes or suffixes to obtain the root form, which might not always be a valid word. It's generally faster but less accurate than lemmatization."
      ],
      "metadata": {
        "id": "kmDDargBi_bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "\n",
        "# Downloading NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "ls = LancasterStemmer()\n",
        "word_list = nltk.word_tokenize(text)\n",
        "\n",
        "# Applying Porter Stemmer\n",
        "porter_stems = [ps.stem(word) for word in word_list]\n",
        "print(\"Porter Stemmer:\", porter_stems)\n",
        "\n",
        "# Applying Lancaster Stemmer\n",
        "lancaster_stems = [ls.stem(word) for word in word_list]\n",
        "print(\"Lancaster Stemmer:\", lancaster_stems)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TNBfBwngvpN",
        "outputId": "b6aaf612-20d2-4c37-efda-0a8a14c553de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer: ['hello', ',', 'i', \"'m\", 'sayantan', 'mukherje', '.', 'i', \"'m\", 'current', 'in', 'djsce', 'as', 'a', 'third-year', 'btech', 'student', '.', 'i', 'have', 'pass', '5', 'semest', '.']\n",
            "Lancaster Stemmer: ['hello', ',', 'i', \"'m\", 'say', 'mukhers', '.', 'i', \"'m\", 'cur', 'in', 'djsce', 'as', 'a', 'third-year', 'btech', 'stud', '.', 'i', 'hav', 'pass', '5', 'semest', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization\n",
        "\n",
        "Lemmatization is the process of transforming a word to its base or root form, known as the \"lemma.\"\n",
        "\n",
        "lemmatization takes into account the context and morphological analysis of the words, ensuring that the root word has meaning and is a valid word in the language. This makes lemmatization more accurate than stemming."
      ],
      "metadata": {
        "id": "GLPvrvGdjIMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Downloading NLTK resources\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "word_list = nltk.word_tokenize(text)\n",
        "\n",
        "# Applying Lemmatization\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in word_list]\n",
        "print(\"Lemmatization:\", lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTWoyntthcQw",
        "outputId": "23320476-bdf4-47ab-a99c-2775ae4e9365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization: ['Hello', ',', 'I', \"'m\", 'Sayantan', 'Mukherjee', '.', 'I', \"'m\", 'Currently', 'in', 'DJSCE', 'As', 'a', 'Third-Year', 'BTECH', 'Student', '.', 'I', 'have', 'passed', '5', 'Semesters', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}